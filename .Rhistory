mean(f1_average)
f1_score_function <- function(observation,prediction){
confusion_matrix <- table(observation,prediction)
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
print(precision, recall)
f1_score <- 2 * (precision*recall)/(precision-recall)
return( f1_score)
}
f1_average <- c()
for (i in  1:8){
dail_sample <- sample(nrow(dail2002),nrow(dail2002)/8, replace=FALSE)
dail_training <- dail2002[-dail_sample,]
dail_sample <- dail2002[dail_sample,]
reg3_1 <- glm(reg3_1$formula, data = dail_training, family=binomial)
reg3_predict <-  predict(reg3_1, dail_sample , type="response")
reg3_wonseat <- rep(0,nrow(dail_sample))
reg3_wonseat[reg3_predict>0.5] <- 1
f1_average <- c(f1_average,f1_score_function(reg3_predict,dail_sample$wonseat))
}
mean(f1_average)
f1_score_function <- function(observation,prediction){
confusion_matrix <- table(observation,prediction)
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
print(precision, recall)
f1_score <- 2 * (precision*recall)/(precision-recall)
return( f1_score)
}
f1_average <- c()
for (i in  1:8){
dail_sample <- sample(nrow(dail2002),nrow(dail2002)/8, replace=FALSE)
dail_training <- dail2002[-dail_sample,]
dail_sample <- dail2002[dail_sample,]
reg3_1 <- glm(reg3_1$formula, data = dail_training, family=binomial)
reg3_predict <-  predict(reg3_1, dail_sample , type="response")
reg3_wonseat <- rep(0,nrow(dail_sample))
reg3_wonseat[reg3_predict>0.5] <- 1
f1_average <- c(f1_average,f1_score_function(reg3_wonseat,dail_sample$wonseat))
}
mean(f1_average)
for (i in  1:8){
dail_sample <- sample(nrow(dail2002),nrow(dail2002)/8, replace=FALSE)
dail_training <- dail2002[-dail_sample,]
dail_sample <- dail2002[dail_sample,]
reg3_1 <- glm(wonseat ~ electorate + votes1997, data = dail_training, family=binomial)
reg3_predict <-  predict(reg3_1, dail_sample , type="response")
reg3_wonseat <- rep(0,nrow(dail_sample))
reg3_wonseat[reg3_predict>0.5] <- 1
f1_average <- c(f1_average,f1_score_function(reg3_wonseat,dail_sample$wonseat))
}
mean(f1_average)
require(class)
require(quantedaData)
require(quantedData)
install.packages("quantedaData")
install.packages("quanteda")
require(quantedaData)
require(quanteda)
?knn
classified <- knn(dail_training, dail_sample, trainclass, k=1)
train <- rbind(iris3[1:25,,1], iris3[1:25,,2], iris3[1:25,,3])
test <- rbind(iris3[26:50,,1], iris3[26:50,,2], iris3[26:50,,3])
cl <- factor(c(rep("s",25), rep("c",25), rep("v",25)))
cl
train <- cbind(dail_training$electorate,dail_training$votes1997)
classified <- knn(train, test, dail_training$wonseat, k=1)
train <- cbind(dail_training$electorate,dail_training$votes1997)
test <- cbind(dail_sample$electorate,dail_sample$votes1997)
classified <- knn(train, test, dail_training$wonseat, k=1)
require(class)
train <- cbind(dail_training$electorate,dail_training$votes1997)
test <- cbind(dail_sample$electorate,dail_sample$votes1997)
classified <- knn(train, test, dail_training$wonseat, k=1)
train <- cbind(dail_training$electorate,dail_training$votes1997)
test <- cbind(dail_sample$electorate,dail_sample$votes1997)
View(test)
dail_training <- na.omit(dail_training)
dail_sample <- na.omit(dail_sample)
train <- cbind(dail_training$electorate,dail_training$votes1997)
test <- cbind(dail_sample$electorate,dail_sample$votes1997)
classified <- knn(train, test, dail_training$wonseat, k=1)
dail_training <- na.omit(dail_training)
dail_sample <- na.omit(dail_sample)
train <- cbind(dail_training$electorate,dail_training$votes1997)
test <- cbind(dail_sample$electorate,dail_sample$votes1997)
classified <- knn(train, test, dail_training$wonseat, k=1)
classified
require(class)
dail_training <- na.omit(dail_training)
dail_sample <- na.omit(dail_sample)
train <- cbind(dail_training$electorate,dail_training$votes1997)
test <- cbind(dail_sample$electorate,dail_sample$votes1997)
classified <- knn(train, test, dail_training$wonseat, k=1)
confusion_matrix <- table(dail_training$wonseat,classified )
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
print(precision, recall)
f1_score <- 2 * (precision*recall)/(precision-recall)
f1_score
mean(classified==dail_training$wonseat)
confusion_matrix <- table(dail_training$wonseat,classified )
dail_training <- na.omit(dail_training)
dail_sample <- na.omit(dail_sample)
train <- cbind(dail_training$electorate,dail_training$votes1997)
test <- cbind(dail_sample$electorate,dail_sample$votes1997)
classified <- knn(train, test, dail_training$wonseat, k=1)
confusion_matrix <- table(dail_training$wonseat,classified )
confusion_matrix <- table(dail_sample$wonseat,classified )
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
print(precision, recall)
f1_score <- 2 * (precision*recall)/(precision-recall)
f1_score
mean(classified==dail_training$wonseat)
confusion_matrix <- table(dail_sample$wonseat,classified )
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
print(precision, recall)
f1_score <- 2 * (precision*recall)/(precision-recall)
f1_score
precision
recall
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
f1_score <- 2 * (precision*recall)/(precision-recall)
f1_score
require(class)
dail_training <- na.omit(dail_training)
dail_sample <- na.omit(dail_sample)
train <- cbind(dail_training$electorate,dail_training$votes1997)
test <- cbind(dail_sample$electorate,dail_sample$votes1997)
classified <- knn(train, test, dail_training$wonseat, k=1)
confusion_matrix <- table(dail_sample$wonseat,classified )
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
f1_score <- 2 * (precision*recall)/(precision+recall)
f1_score
mean(classified==dail_training$wonseat)
confusion_matrix <- table(dail_sample$wonseat,classified )
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
f1_score <- 2 * (precision*recall)/(precision+recall)
f1_score
mean(classified==dail_training$wonseat)
mean(classified==dail_sample$wonseat)
require(class)
dail_training <- na.omit(dail_training)
dail_sample <- na.omit(dail_sample)
train <- cbind(dail_training$electorate,dail_training$votes1997)
test <- cbind(dail_sample$electorate,dail_sample$votes1997)
classified <- knn(train, test, dail_training$wonseat, k=1)
confusion_matrix <- table(dail_sample$wonseat,classified )
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
f1_score <- 2 * (precision*recall)/(precision+recall)
f1_score
mean(classified==dail_sample$wonseat)
classified <- knn(train, test, dail_training$wonseat, k=3)
confusion_matrix <- table(dail_sample$wonseat,classified )
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
f1_score <- 2 * (precision*recall)/(precision+recall)
f1_score
mean(classified==dail_sample$wonseat)
classified <- knn(train, test, dail_training$wonseat, k=3)
confusion_matrix <- table(dail_sample$wonseat,classified )
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
f1_score <- 2 * (precision*recall)/(precision+recall)
f1_score
mean(classified==dail_sample$wonseat)
classified <- knn(train, test, dail_training$wonseat, k=5)
classified <- knn(train, test, dail_training$wonseat, k=5)
confusion_matrix <- table(dail_sample$wonseat,classified )
true_positive <- confusion_matrix[1,1]
false_positive <- confusion_matrix[2,1]
false_negative <- confusion_matrix[1,2]
precision <- true_positive/(true_positive+false_positive)
recall <- true_positive/(true_positive+false_negative)
print(confusion_matrix)
f1_score <- 2 * (precision*recall)/(precision+recall)
f1_score
mean(classified==dail_sample$wonseat)
library(quanteda)
inaugTexts <-inaugTexts
inaug_corpus <- corpus(inaugTexts)
kwic(inaugCorpus, "crisis", 3)
mydfm <- dfm(inaugCorpus, ignoredFeatures=stopwords("english"))
topfeatures(mydfm, 20)
mydfm <- dfm(inaugCorpus, groups = "President")
docnames(mydfm)
topfeatures(mydfm, 20)
mydfm <- dfm(inaugCorpus, groups = "President", ignoredFeatures=stopwords("english"))
topfeatures(mydfm, 20)
mydfm <- dfm(inaugCorpus, ignoredFeatures=stopwords("english"))
topfeatures(mydfm, 20)
obamadfm <- dfm(subset(inaugCorpus, President=="Obama"))
plot(obamadfm)
obamadfm <- dfm(subset(inaugCorpus, President=="Obama"),ignoredFeatures=stopwords("english"))
plot(obamadfm)
tekst <- data(exampleString)
tekst <- data(exampleString)
tekst <- data(exampleString)
toLower(tekst)
tekst <- data(exampleString)
toLower(tekst)
tekst <- data(exampleString)
tekst <- toLower(tekst)
tekst
View(tekst)
tekst <- data(exampleString)
?tokenize
tokenize(exampleString)
tekst <- data(exampleString)
tekst <- toLower(tekst)
tokenize(exampleString)
tekst <- data(exampleString)
tekst <- toLower(tekst)
tekst <- data(exampleString)
tekst <- toLower(tekst)
?tokenize
tokenize(exampleString)
tokenize(exampleString, what = "sentence")
tekst <- tokenize(exampleString, what = "sentence")
wordstem(tekst)
tekst <- tokenize(exampleString)
wordstem(tekst)
require(tm)
install.packages("tm")
require(tm)
crude <- tm_map(crude, content_transformer(tolower))
data("crude")
crude <- tm_map(crude, content_transformer(tolower))
crude <- tm_map(crude, removePunctuation)
crude <- tm_map(crude, removeNumbers)
crude <- tm_map(crude, stemDocument)
tdm <- TermDocumentMatrix(crude)
crude
crudeCorpus <- corpus(crude)
crudeDfm <- dfm(crudeCorpus)
data("crude")
crude
data("crude")
crude <- tm_map(crude, content_transformer(tolower))
crude <- tm_map(crude, removePunctuation)
crude <- tm_map(crude, removeNumbers)
crude <- tm_map(crude, stemDocument)
tdm <- TermDocumentMatrix(crude)
crudeCorpus <- corpus(crude)
crudeDfm <- dfm(crudeCorpus)
```{r}
str(tdm)
```
str(tdm)
head(tdm$dimnames$Terms, 20)
head(tdm$dimnames$Terms, 20)
features_quanteda <- features(crudeDfm)
head(features_quanteda, 20)
str(crudeDfm)
object.size(crudeDfm)
object.size(tdm)
library(twitteR)
install.packages("twitterR")
library(twitteR)
library(twitteR)
install.packages("twitterR")
?setRepositories
install.packages(twitterR)
setRepositories(ind = c(1:6, 8))
install.packages("twitterR")
install.packages(c("arules", "ca", "e1071", "gstat", "intervals", "scales", "xts"))
install.packages("C:/Users/Hubert/Desktop/twitteR_1.1.9.tar.gz", repos = NULL, type = "source")
install.packages("C:/Users/Hubert/Desktop/twitteR_1.1.9 (1).zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Hubert/Desktop/twitteR_1.1.9.tar.gz", repos = NULL, type = "source")
install.packages("twitterR")
curl http://bioconductor.org/packages/3.1/bioc/src/contrib/PACKAGES
install.packages("twitteR")
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
library(twitteR)
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
library(twitteR)
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
library(twitteR)
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
results <- searchTwitter('text analysis', n=50)
df <- as.data.frame(t(sapply(results, as.data.frame)))
library(twitteR)
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
library(twitteR)
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
library(twitteR)
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
setup_twitter_oauth('ZOHJIRAwnw23FhvFWyUg','HTfEcEmRRDcx0ZsJ5CHOcmPc84AfDOp5VvIXwt0oY','778251283-ZkDTfl3IbIFZFXlVokA6Gpc19TZPyov3wucZ0XaB','8vgPnpEWP3qhvILmTLXVb9RslwcEwVVeKOo4KCYHOY')
results <- searchTwitter('text analysis', n=50)
df <- as.data.frame(t(sapply(results, as.data.frame)))
usdf <- as.data.frame(us)
setwd("C:/Users/Hubert/Desktop/master-thesis/master-thesis/")
ludnosc <- read.csv("rezultaty/ludnosc.csv")
setwd("C:/Users/Hubert/Desktop/master-thesis/master-thesis/")
getwd()
#Ludnosc
ludnosc <- read.csv("rezultaty/ludnosc.csv")
ludnosc <- ludnosc[,-2]
ludnosc <- ludnosc[,-5]
ludnosc$mezczyzna[ludnosc$mezczyzna==1] <- "Mezczyzna"
ludnosc$mezczyzna[ludnosc$mezczyzna==0] <- "Kobieta"
ludnosc$wyksztalcenie[ludnosc$wyksztalcenie==0] <- "Brak"
ludnosc$wyksztalcenie[ludnosc$wyksztalcenie==1] <- "Podstawowe"
ludnosc$wyksztalcenie[ludnosc$wyksztalcenie==2] <- "Zawodowe"
ludnosc$wyksztalcenie[ludnosc$wyksztalcenie==3] <- "Srednie"
ludnosc$wyksztalcenie[ludnosc$wyksztalcenie==4] <- "Wyzsze"
zainteresowania <- as.data.frame(colSums(ludnosc[5:27]))
colnames(zainteresowania) <- "Ilość"
rownames(zainteresowania) <- c("Moda","Gotowanie","Finanse","Kultura","Historia","Koncerty","Motoryzacja","Kosmetyki","Malarstwo","Ogrodnictwo","Gry","Sport","Boks","Fotografia","Kultura alternatywna","Nightlife","Teatr","Ksiazka","Historia polski","Natura","Piwowarstwo","Muzyka klasyczna","Ksiazki")
library(xtable)
print(xtable(zainteresowania))
png("tekst/pictures/ludnosc.png")
par(mfrow = c(2,2))
hist(ludnosc$wiek, main="Histogram zmiennej wiek", xlab = "Wiek")
hist(ludnosc$zarobki, main="Histogram zmiennej zarobki", xlab = "Zarobki" )
plot(as.factor(ludnosc$wyksztalcenie), main="Histogram zmiennej wyksztalcenie")
plot(as.factor(ludnosc$mezczyzna), main="Histogram zmiennej płeć")
dev.off()
#Rozklady
wyksztalcenie <- read.csv("dane/wyksztalcenie.csv")
k_w <- wyksztalcenie[wyksztalcenie$Plec=="Kobieta",]
m_w <- wyksztalcenie[wyksztalcenie$Plec=="Mezczyzna",]
par(mfrow = c(1,1))
png("tekst/pictures/wyksztalcenie.png")
plot(k_w$p, col="red", xaxt = 'n',xlab="Wykształcenie", ylab="Prawdopodobienstwo", main = 'Rozkład zmiennej wykształcenie')
axis(1, at=1:4,k_w$Wyksztalcenie)
lines(k_w$p, col="red")
points(m_w$p, col="green")
lines(m_w$p, col="green")
dev.off()
wiek <- read.csv("dane/wiek.csv",header=FALSE)
png("tekst/pictures/wiek.png")
plot(wiek, ylab="Prawdopodobienstwo", xlab="Wiek", main = 'Rozkład zmiennej wiek')
dev.off()
produkty <- read.csv("rezultaty/produkty.csv")
print(xtable(produkty))
dev.off()
przewidywania <- read.csv("rezultaty/przewidywania.csv")
mean(przewidywania$lm)
#Prognozy
prognoza <- read.csv("rezultaty/jeden/prognoza.csv")
prognoza <- aggregate(prognoza[3:4], by=list(prognoza$Tura), FUN="sum")
png("tekst/pictures/prog.png")
plot(prognoza$Przewidywane, col="blue", ylim=c(0,as.integer(max(prognoza)*1.25)), xaxt = 'n',xlab="Tura", ylab="Ilość produktów", main = 'Prognoza sprzedaży i rzeczywista sprzedaż produktów')
axis(1, at=1:nrow(prognoza),prognoza$Group.1)
lines(prognoza$Przewidywane, col="blue")
points(prognoza$Sprzedaz, col="green")
lines(prognoza$Sprzedaz, col="green")
dev.off()
#Wyniki firmy bez optymalizacji
koszty <- read.csv("rezultaty/zero/koszty.csv")
koszty <- aggregate(koszty[6], by=list(koszty$Tura), FUN="sum")
przychody <- read.csv("rezultaty/zero/przychody.csv")
przychody <- aggregate(przychody[5], by=list(przychody$Tura), FUN="sum")
zysk <- read.csv("rezultaty/zero/zysk.csv")
trasy <- read.csv("rezultaty/zero/trasy.csv")
trasy <- aggregate(trasy[c(3,4,5)], by=list(trasy$Tura), FUN="mean")
png("tekst/pictures/brak_algorytmu/wyniki.png")
plot(koszty$Koszt.w.turze, col="red", ylim=c(0,as.integer(max(przychody)*1.25)), xaxt = 'n',xlab="Tura", ylab="PLN", main = 'Wyniki symulacji bez optymalizacji')
axis(1, at=1:nrow(koszty),koszty$Tura)
lines(koszty$Koszt.w.turze, col="red")
points(przychody$Przychod, col="green")
lines(przychody$Przychod, col="green")
points(zysk$Zysk, col="blue")
lines(zysk$Zysk, col="blue")
dev.off()
png("tekst/pictures/brak_algorytmu/trasy.png")
plot(trasy$Koszt, col="red", ylim=c(as.integer(min(trasy)-1.25),as.integer(max(trasy)*1.25)), xaxt = 'n',xlab="Tura", ylab="PLN", main = 'Średnie wyniki tras')
axis(1, at=1:nrow(trasy),trasy$Tura)
lines(trasy$Koszt, col="red")
points(trasy$Przychod, col="green")
lines(trasy$Przychod, col="green")
points(trasy$Zysk, col="blue")
lines(trasy$Zysk, col="blue")
dev.off()
trasy <- read.csv("rezultaty/jeden/trasy.csv")
png("tekst/pictures/brak_algorytmu/trasy2.png")
ggplot(data = trasy, aes(x = trasy$Tura, y=trasy$Zysk, color = trasy$Symbol)) + ggtitle("Zysk per trasa")+xlab("Zysk") + ylab("Tura")+ geom_line(aes(group=trasy$Symbol)) +geom_point() + theme_bw() + geom_hline(linetype="dashed",aes(yintercept=0))
dev.off()
#Wyniki firmy z optymalizacji
koszty <- read.csv("rezultaty/jeden/koszty.csv")
koszty <- aggregate(koszty[6], by=list(koszty$Tura), FUN="sum")
przychody <- read.csv("rezultaty/jeden/przychody.csv")
przychody <- aggregate(przychody[5], by=list(przychody$Tura), FUN="sum")
zysk <- read.csv("rezultaty/jeden/zysk.csv")
trasy <- read.csv("rezultaty/jeden/trasy.csv")
trasy <- aggregate(trasy[c(3,4,5)], by=list(trasy$Tura), FUN="mean")
png("tekst/pictures/algorytm_brak_skali/wyniki.png")
plot(koszty$Koszt.w.turze, col="red", ylim=c(0,as.integer(max(przychody)*1.25)), xaxt = 'n',xlab="Tura", ylab="PLN", main = 'Wyniki symulacji bez optymalizacji')
axis(1, at=1:nrow(koszty),koszty$Tura)
abline(v = 15, lty = 2)
sredni_zysk = c(1:30)
sredni_zysk[c(1:16)] = mean(zysk$Zysk[c(1:16)])
sredni_zysk[c(16:30)] = mean(zysk$Zysk[c(16:25)])
sredni_zysk
lines(sredni_zysk,lty = 3,col="purple" )
lines(koszty$Koszt.w.turze, col="red")
points(przychody$Przychod, col="green")
lines(przychody$Przychod, col="green")
points(zysk$Zysk, col="blue")
lines(zysk$Zysk, col="blue")
dev.off()
png("tekst/pictures/algorytm_brak_skali/trasy.png")
plot(trasy$Koszt, col="red", ylim=c(as.integer(min(trasy)-1.25),as.integer(max(trasy)*1.25)), xaxt = 'n',xlab="Tura", ylab="PLN", main = 'Średnie wyniki tras')
axis(1, at=1:nrow(trasy),trasy$Tura)
lines(trasy$Koszt, col="red")
points(trasy$Przychod, col="green")
lines(trasy$Przychod, col="green")
points(trasy$Zysk, col="blue")
lines(trasy$Zysk, col="blue")
dev.off()
trasy <- read.csv("rezultaty/jeden/trasy.csv")
png("tekst/pictures/algorytm_brak_skali/trasy2.png")
ggplot(data = trasy, aes(x = trasy$Tura, y=trasy$Zysk, color = trasy$Symbol)) + ggtitle("Zysk per trasa")+xlab("Zysk") + ylab("Tura")+ geom_line(aes(group=trasy$Symbol)) +geom_point() + theme_bw() + geom_hline(linetype="dashed",aes(yintercept=0))
dev.off()
#Wyniki firmy z optymalizacji 2
koszty <- read.csv("rezultaty/dwa/koszty.csv")
koszty <- aggregate(koszty[6], by=list(koszty$Tura), FUN="sum")
przychody <- read.csv("rezultaty/dwa/przychody.csv")
przychody <- aggregate(przychody[5], by=list(przychody$Tura), FUN="sum")
zysk <- read.csv("rezultaty/dwa/zysk.csv")
trasy <- read.csv("rezultaty/dwa/trasy.csv")
trasy <- aggregate(trasy[c(3,4,5)], by=list(trasy$Tura), FUN="mean")
png("tekst/pictures/algorytm_skala/wyniki.png")
plot(koszty$Koszt.w.turze, col="red", ylim=c(0,as.integer(max(przychody)*1.25)), xaxt = 'n',xlab="Tura", ylab="PLN", main = 'Wyniki symulacji bez optymalizacji')
axis(1, at=1:nrow(koszty),koszty$Tura)
abline(v = 15, lty = 2)
sredni_zysk = c(1:30)
sredni_zysk[c(1:16)] = mean(zysk$Zysk[c(1:16)])
sredni_zysk[c(16:30)] = mean(zysk$Zysk[c(16:16)])
sredni_zysk
lines(sredni_zysk,lty = 3,col="purple" )
lines(koszty$Koszt.w.turze, col="red")
points(przychody$Przychod, col="green")
lines(przychody$Przychod, col="green")
points(zysk$Zysk, col="blue")
lines(zysk$Zysk, col="blue")
dev.off()
png("tekst/pictures/algorytm_skala/trasy.png")
plot(trasy$Koszt, col="red", ylim=c(as.integer(min(trasy)-1.25),as.integer(max(trasy)*1.25)), xaxt = 'n',xlab="Tura", ylab="PLN", main = 'Średnie wyniki tras')
axis(1, at=1:nrow(trasy),trasy$Tura)
lines(trasy$Koszt, col="red")
points(trasy$Przychod, col="green")
lines(trasy$Przychod, col="green")
points(trasy$Zysk, col="blue")
lines(trasy$Zysk, col="blue")
dev.off()
trasy <- read.csv("rezultaty/dwa/trasy.csv")
png("tekst/pictures/algorytm_skala/trasy2.png")
ggplot(data = trasy, aes(x = trasy$Tura, y=trasy$Zysk, color = trasy$Symbol)) + ggtitle("Zysk per trasa")+xlab("Zysk") + ylab("Tura")+ geom_line(aes(group=trasy$Symbol)) +geom_point() + theme_bw() + geom_hline(linetype="dashed",aes(yintercept=0))
dev.off()
